{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.transforms import ToTensor,ToPILImage, Resize,Compose, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD,Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#https://github.com/sairin1202/fcn32-pytorch/blob/master/pytorch-fcn32.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relabel:\n",
    "    def __init__(self,olabel,nlabel):\n",
    "        self.olabel=olabel\n",
    "        self.nlabel=nlabel\n",
    "\n",
    "    def __call__(self,tensor):\n",
    "        assert isinstance(tensor,torch.LongTensor) \n",
    "        tensor[tensor==self.olabel]=self.nlabel\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ToLabel:\n",
    "    def __call__(self,image):\n",
    "        return torch.from_numpy(np.array(image)).long().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file):\n",
    "    return Image.open(file)\n",
    "\n",
    "def get_images(filename):\n",
    "    image_names=np.loadtxt(filename,dtype=np.str)[0:5]\n",
    "    return image_names,len(image_names)\n",
    "\n",
    "input_transform=Compose([\n",
    "                        Resize((512,512)),\n",
    "                        ToTensor(),\n",
    "                        Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "label_transform=Compose([\n",
    "                        Resize((512,512)),\n",
    "                        ToLabel(),\n",
    "                        Relabel(256,0)\n",
    "])\n",
    "\n",
    "class gdi(Dataset):\n",
    "    \n",
    "    def __init__(self,data_dir,label_dir,train_file,input_transform=None,label_transform=None):\n",
    "        self.data_dir=data_dir\n",
    "        self.label_dir=label_dir\n",
    "        self.input_transform=input_transform\n",
    "        self.label_transform=label_transform\n",
    "        self.train_file=train_file\n",
    "        self.train_image_names,self.train_length=get_images(train_file)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        filename=self.train_image_names[index]\n",
    "        with open(self.data_dir+str(filename)+'.jpg','rb') as f:\n",
    "            image=load_image(f).convert('RGB')\n",
    "        with open(self.label_dir+str(filename)+'.png','rb') as f:\n",
    "            label=load_image(f).convert('L')\n",
    "\n",
    "        if self.input_transform is not None:\n",
    "            image=self.input_transform(image)\n",
    "        if self.label_transform is not None:\n",
    "            label=self.label_transform(label)\n",
    "        \n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class fcn32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fcn32,self).__init__()\n",
    "        self.pretrained_model=vgg16(pretrained=True)\n",
    "        features,classifiers=list(self.pretrained_model.features.children()),list(self.pretrained_model.classifier.children())\n",
    "\n",
    "        features[0].padding=(100,100)\n",
    "        self.features_map=nn.Sequential(*features)\n",
    "        self.conv=nn.Sequential(nn.Conv2d(512,4096,7),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(),\n",
    "                                nn.Conv2d(4096,4096,1),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout()\n",
    "                                )\n",
    "        self.score_fr=nn.Conv2d(4096,256,1) \n",
    "        self.upscore=nn.ConvTranspose2d(256,256,64,32)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_size=x.size() #[1, 3, 512, 512]\n",
    "        pool=self.conv(self.features_map(x)) #[1, 4096, 12, 12]\n",
    "        score_fr=self.score_fr(pool) #[1, 256, 12, 12]\n",
    "        upscore=self.upscore(score_fr) #[1,256,12,12]\n",
    "        return upscore[:,:,16:(16+x_size[2]),16:(16+x_size[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb1396be69544aab3862f5bafef70d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fcn=fcn32()\n",
    "fcn=fcn.cuda()\n",
    "\n",
    "\n",
    "data_dir=\"/kaggle/input/graphic-design-importance/gd_train/gd_train/\"\n",
    "train_txt_path=\"/kaggle/input/train-file/train.txt\"\n",
    "label_dir=\"/kaggle/input/graphic-design-importance/gd_imp_train/gd_imp_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,batch_size,epoches):\n",
    "    model.train()\n",
    "\n",
    "    #weight=torch.ones(21)\n",
    "    #weight[0]=0\n",
    "\n",
    "    loader=DataLoader(gdi(data_dir,label_dir,train_txt_path,input_transform,label_transform),\n",
    "                      num_workers=4,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=Adam(model.parameters(),1e-5)\n",
    "\n",
    "    for epoch in range(1,epoches+1):\n",
    "        for step,(images,labels) in enumerate(loader):\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "            print('label:',labels.size())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            inputs=Variable(images)\n",
    "            targets=Variable(labels)\n",
    "            targets = targets.squeeze(1)\n",
    "            outputs=model(inputs)\n",
    "            \n",
    "            \n",
    "            # inputs need to be of size [batch, n_class, dim1, dim2]\n",
    "            # targets need to be of size [batch, dim1, dim2], in which values in dims are between [0,n_class)\n",
    "            \n",
    "            loss=criterion(outputs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step%1==0:\n",
    "                print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x size torch.Size([1, 3, 512, 512])\n",
    "\n",
    "pool size torch.Size([1, 4096, 16, 16])\n",
    "\n",
    "score size: torch.Size([1, 256, 16, 16])\n",
    "\n",
    "upscore size torch.Size([1, 256, 544, 544])\n",
    "\n",
    "what to return: torch.Size([1, 256, 512, 512])\n",
    "\n",
    "output: torch.Size([1, 256, 512, 512])\n",
    "\n",
    "target: torch.Size([1, 1, 512, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5452, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.5449, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5443, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.5431, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5419, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.5397, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5371, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.5320, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5262, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.5189, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.5079, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.4887, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.4615, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.4595, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.3881, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.3885, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.3253, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.1490, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(5.1155, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(5.0069, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.8683, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.7886, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5460, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.9399, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.8240, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.4707, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5208, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.8533, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.4301, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.7513, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.4903, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.5091, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.6360, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.2379, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.4676, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.4604, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.6383, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.1100, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5958, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.0877, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.2869, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.5011, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.4814, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.1445, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.0128, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.8043, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.9524, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.7897, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.2770, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.2264, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.3946, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.9920, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.3755, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.9524, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.9769, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.5139, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.3470, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.8653, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.9849, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.3861, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.8943, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.4680, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5408, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.4355, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5252, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.4110, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.7968, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.4846, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.0033, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.1146, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.2687, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.6839, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.5185, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.2670, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(4.2411, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(3.6461, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.9538, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.0529, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([3, 1, 512, 512])\n",
      "tensor(3.6827, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "tensor(4.4314, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "train(fcn,3,40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "15370df7b63a4831bfb9b6a55b0a313c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8ec5d99d2f584cdda183ea662ac954da",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d44a22ca598840958b7acec4cdc8c8e7",
       "value": " 528M/528M [00:08&lt;00:00, 66.1MB/s]"
      }
     },
     "2a3c50cf303747e196603a7c3c77a12d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9353ef1a24ab47538da4980cc123766d",
       "max": 553433881.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_32263df1de2f49acbf478751358239f7",
       "value": 553433881.0
      }
     },
     "32263df1de2f49acbf478751358239f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "7fb1396be69544aab3862f5bafef70d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2a3c50cf303747e196603a7c3c77a12d",
        "IPY_MODEL_15370df7b63a4831bfb9b6a55b0a313c"
       ],
       "layout": "IPY_MODEL_be05902dcab843c6abd4863de1cb79f4"
      }
     },
     "8ec5d99d2f584cdda183ea662ac954da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9353ef1a24ab47538da4980cc123766d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be05902dcab843c6abd4863de1cb79f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d44a22ca598840958b7acec4cdc8c8e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
